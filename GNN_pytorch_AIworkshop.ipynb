{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR9mjubPFfLw"
   },
   "source": [
    "# CAMELS Rockstar Halos: GNN Classification Project\n",
    "\n",
    "This notebook will guide you through:\n",
    "- Downloading Rockstar halo catalogs from the CAMELS simulations\n",
    "- Preparing the data into a graph format\n",
    "- Visualizing the halo connections\n",
    "- Building a Graph Neural Network (GNN) model\n",
    "- Training and evaluating the model\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Install and Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3532,
     "status": "ok",
     "timestamp": 1747986997396,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "HEOp4W3SFj7r",
    "outputId": "9f460908-6431-4e68-99b5-b30a0f415898"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torch-geometric networkx matplotlib torchsummary\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwsV5PfrF7oK"
   },
   "source": [
    "## Step 2: Download CAMELS Rockstar Data\n",
    "\n",
    "We will download a subset of the Rockstar catalogs.\n",
    "\n",
    "Source: [CAMELS Data Portal](https://users.flatironinstitute.org/~camels/)\n",
    "\n",
    "For this example, we'll use one of the available catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746610306666,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "VA3Ab-e6FoIb"
   },
   "outputs": [],
   "source": [
    "# Download Rockstar halo catalog\n",
    "!wget https://users.flatironinstitute.org/~camels/Rockstar/CAMELS-SAM/LH/LH_832/Rockstar/out_66.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37352,
     "status": "ok",
     "timestamp": 1747986592754,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "L9xgU2fi90EH",
    "outputId": "f07a9961-f1e2-4578-fcc9-4cec21e2cdaf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "data_dir = \"/content/drive/MyDrive/data\"  # Specify the desired path in your Google Drive\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Move the downloaded file to the Google Drive directory\n",
    "!mv /content/out_66.list /content/drive/MyDrive/data/\n",
    "\n",
    "# Read the file from Google Drive\n",
    "file_path = \"/content/drive/MyDrive/data/out_66.list\"\n",
    "try:\n",
    "  with open(file_path, 'r') as file:\n",
    "      # Process the file content here\n",
    "      # For example, read lines, analyze data, etc.\n",
    "      lines = file.readlines()\n",
    "      # Print the first few lines to verify\n",
    "      print(\"First 5 lines of the file:\")\n",
    "      for i in range(5):\n",
    "          print(lines[i].strip())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1683,
     "status": "ok",
     "timestamp": 1747986594438,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "nYNBQGaH_az_",
    "outputId": "23be9a84-80ce-4e3f-8636-0336c5125e95"
   },
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "      print(\"First 17 lines of the file:\")\n",
    "      for i in range(17):\n",
    "          print(lines[i].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr051uRQGOmn"
   },
   "source": [
    "## Step 3: Load and Preprocess the Data\n",
    "\n",
    "We'll load the Rockstar halo catalog, select a few features (position, velocity, mass), and construct a graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBhYbKRy5MAn"
   },
   "source": [
    "For the CAMEL Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12033,
     "status": "ok",
     "timestamp": 1747986606487,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "1SzenzzvOXls",
    "outputId": "638ecc91-6f60-4f99-abcf-bdcc77626236"
   },
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/data/out_66.list\"\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "positions = []\n",
    "masses = []\n",
    "velocities = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()[16:]  # Skip the header (first 16 lines)\n",
    "        for line in lines:\n",
    "            data = line.strip().split()\n",
    "            try:\n",
    "                positions.append([float(data[8]), float(data[9]), float(data[10])])\n",
    "                masses.append(float(data[2]))\n",
    "                velocities.append([float(data[11]), float(data[12]), float(data[13])])\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    position = np.array(positions)\n",
    "    mass = np.array(masses)\n",
    "    velocity = np.array(velocities)\n",
    "\n",
    "    print(\"Shape of position array:\", position.shape)\n",
    "    print(\"Shape of mass array:\", mass.shape)\n",
    "    print(\"Shape of velocity array:\", velocity.shape)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mHt0RZS--AY"
   },
   "source": [
    "## Step 4: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1747986607950,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "bnXQQskEHdyb",
    "outputId": "6e37d810-4cce-4e1f-d3ba-ae844929d062"
   },
   "outputs": [],
   "source": [
    "# Apply the lower limit\n",
    "# mass_filtered = mass[mass >= 10**12]\n",
    "\n",
    "# Create the histogram with a logarithmic scale\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.hist(mass_filtered, bins=np.logspace(np.log10(min(mass)), np.log10(max(mass)), 50), edgecolor='black')  # Adjust bins as needed\n",
    "plt.hist(mass, bins=np.logspace(np.log10(min(mass)), np.log10(max(mass)), 50), edgecolor='black')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')  # Use logarithmic scale for y-axis\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mass (log scale)')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1747986608076,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "C3xTMVkWI8oQ",
    "outputId": "a70ae4fe-9998-4af9-9940-aaff2a753726"
   },
   "outputs": [],
   "source": [
    "# Plotting the distrubution of x,y, z in the positions for those with mass more than 10^12\n",
    "\n",
    "# Filter positions based on mass\n",
    "mass_cut = 10**12.5\n",
    "filtered_positions = position[mass >= mass_cut]\n",
    "\n",
    "# Extract x, y, and z coordinates\n",
    "x = filtered_positions[:, 0]\n",
    "y = filtered_positions[:, 1]\n",
    "z = filtered_positions[:, 2]\n",
    "\n",
    "# Create histograms\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(x, bins=50)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of x')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(y, bins=50)\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of y')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(z, bins=50)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of z')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1747986608819,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "YIl0wQm5GU3c",
    "outputId": "da470136-b380-4515-e31a-05202fbb9907"
   },
   "outputs": [],
   "source": [
    "# A 3d plot with x,y,z of halos and mass on the colorbar\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Filter positions and masses based on the mass condition\n",
    "filtered_positions = position[mass >= mass_cut]\n",
    "filtered_masses = mass[mass >= mass_cut]\n",
    "\n",
    "# Extract x, y, and z coordinates\n",
    "x = filtered_positions[:, 0]\n",
    "y = filtered_positions[:, 1]\n",
    "z = filtered_positions[:, 2]\n",
    "print(x.shape, y.shape, z.shape)\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the points with size proportional to mass\n",
    "scatter = ax.scatter(x, y, z, s=filtered_masses / 1e12, c=filtered_masses, cmap='viridis') # Adjust scaling as needed\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.set_title('3D Scatter Plot of Halo Positions with Mass as Size')\n",
    "\n",
    "# Add a colorbar to indicate mass\n",
    "fig.colorbar(scatter, label='Mass')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8ISr_mxX4PD"
   },
   "source": [
    "## Step 4: Build the Graph\n",
    "\n",
    "We will build a simple spatial proximity graph using nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "executionInfo": {
     "elapsed": 31203,
     "status": "ok",
     "timestamp": 1747986640034,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "Dp_y7I_I_Op5",
    "outputId": "77dfce7a-cda7-419c-dc14-a9ddc0a8a2a0"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "filtered_positions = position[mass >= mass_cut]\n",
    "filtered_masses = mass[mass >= mass_cut]\n",
    "\n",
    "# Calculate distance matrix\n",
    "distance_matrix = np.linalg.norm(filtered_positions[:, np.newaxis, :] - filtered_positions[np.newaxis, :, :], axis=2)\n",
    "\n",
    "# Create graph\n",
    "graph = nx.Graph()\n",
    "num_nodes = len(filtered_positions)\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    graph.add_node(i, pos=filtered_positions[i], mass=filtered_masses[i])\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    for j in range(i + 1, num_nodes):  # Avoid duplicate edges\n",
    "        if distance_matrix[i, j] < 10:  # Edge if distance < 10\n",
    "            graph.add_edge(i, j)\n",
    "\n",
    "# Plot the graph (3D)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get node positions from the graph\n",
    "node_positions = nx.get_node_attributes(graph, 'pos')\n",
    "\n",
    "# Draw nodes\n",
    "# nx.draw_networkx_nodes(graph, node_positions, node_size=10, ax=ax)  # Reduced node size for better visualization\n",
    "\n",
    "\n",
    "# Draw edges (iterate through edges and plot as lines)\n",
    "for u, v in graph.edges():\n",
    "    pos_u = node_positions[u]\n",
    "    pos_v = node_positions[v]\n",
    "    ax.plot([pos_u[0], pos_v[0]], [pos_u[1], pos_v[1]], [pos_u[2], pos_v[2]], color='gray', linewidth=0.5) # Plot each edge as a line\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('3D Graph of Halos')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Number of connected components (graphs)\n",
    "num_graphs = nx.number_connected_components(graph)\n",
    "print(f\"Number of graphs: {num_graphs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1747986640526,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "TGC40gkuInaW",
    "outputId": "738b3be2-fc47-4988-f0f8-f3f1a23cee03"
   },
   "outputs": [],
   "source": [
    "num_nodes = graph.number_of_nodes()\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "\n",
    "degree_sequence = [graph.degree(node) for node in graph.nodes()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(degree_sequence, bins=range(max(degree_sequence) + 2), align='left', edgecolor='black') #histogram\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Node Degrees\")\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1747986640878,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "patLtU8hLOYM",
    "outputId": "bd5308de-c0f9-49cf-9fc2-907a008c4b0a"
   },
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(graph)\n",
    "node_degrees = list(dict(graph.degree()).values())\n",
    "\n",
    "# Count nodes with degree > 20\n",
    "degree_critria = 20\n",
    "nodes_above = sum(1 for degree in node_degrees if degree > degree_critria)\n",
    "#print(f\"Number of nodes with degree greater than 20: {nodes_above}\")\n",
    "\n",
    "\n",
    "# 3D scatter plot with node degree as size\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get node positions from the graph\n",
    "node_positions = nx.get_node_attributes(graph, 'pos')\n",
    "node_x = [pos[0] for pos in node_positions.values()]\n",
    "node_y = [pos[1] for pos in node_positions.values()]\n",
    "node_z = [pos[2] for pos in node_positions.values()]\n",
    "\n",
    "\n",
    "scatter = ax.scatter(node_x, node_y, node_z, s=node_degrees, c=node_degrees, cmap='viridis')  # Use node degree for size and color\n",
    "\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.set_title('3D Scatter Plot of Nodes with Degree as Size')\n",
    "\n",
    "# Add a colorbar to indicate degree\n",
    "fig.colorbar(scatter, label='Node Degree')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0G_u9rVX9aX"
   },
   "source": [
    "## Step 5: Preparing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1747986652271,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "9OqcQowQKOPp",
    "outputId": "74ed7695-c82c-4521-e5b4-4d9527dafd4e"
   },
   "outputs": [],
   "source": [
    "# Create node features (labels) based on degree\n",
    "node_labels = []\n",
    "for node in graph.nodes():\n",
    "    degree = graph.degree(node)\n",
    "    if degree > degree_critria:\n",
    "        node_labels.append(0)  # Cluster node\n",
    "    else:\n",
    "        node_labels.append(1)  # Void node\n",
    "\n",
    "node_labels = np.array(node_labels)\n",
    "\n",
    "# Now you have node features (labels) in the 'node_labels' array. You can use this in the next steps for your GNN.\n",
    "\n",
    "# Example: Convert to PyTorch Geometric Data object\n",
    "edge_index = torch.tensor(list(graph.edges)).t().contiguous()\n",
    "x = torch.tensor(node_labels, dtype=torch.long) # Node features are the labels\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmWMhoQ3YCY-"
   },
   "source": [
    "## Step 6: Define the GNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1747987496660,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "ucyVUmV9z-M8"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Cr_REHqYJp5"
   },
   "source": [
    "## Step 7: Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1846,
     "status": "ok",
     "timestamp": 1747987506225,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "xaDFnIN4P5Qw",
    "outputId": "a8258019-bd88-4653-d615-462e3fce421e"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate train and test masks\n",
    "num_nodes = data.x.shape[0]\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# Assuming a 80/20 split for train/test\n",
    "train_idx, test_idx = train_test_split(range(num_nodes), test_size=0.2, random_state=42)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "data.y = torch.tensor(node_labels, dtype=torch.long) #Assuming node_labels are your ground truth labels\n",
    "\n",
    "# Initialize the model\n",
    "model = GNN(num_node_features=1, hidden_channels=64, num_classes=2)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()\n",
    "    # Reshape data.x to have 2 dimensions\n",
    "    out = model(data.x.unsqueeze(1).float(), data.edge_index) # Reshape data.x to have 2 dimensions\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval() # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x.unsqueeze(1).float(), data.edge_index).argmax(dim=1) # Reshape data.x to have 2 dimensions during evaluation as well\n",
    "    acc = accuracy_score(node_labels, pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ow73EnFbYXyU"
   },
   "source": [
    "## Step 8: Evaluate the Model\n",
    "Let's Calculate the accuracy, precision, Recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778
    },
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1747987512083,
     "user": {
      "displayName": "Farida Farsian",
      "userId": "01139163618797543099"
     },
     "user_tz": -120
    },
    "id": "18T0tDQC0CsR",
    "outputId": "10201d3b-88b2-49d6-8649-fc71e0d75234"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x.unsqueeze(1).float(), data.edge_index).argmax(dim=1)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(node_labels, pred, average='weighted')\n",
    "    recall = recall_score(node_labels, pred, average='weighted')\n",
    "    f1 = f1_score(node_labels, pred, average='weighted')\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(node_labels, pred))\n",
    "\n",
    "    # Compute and plot the confusion matrix\n",
    "    conf_matrix = confusion_matrix(node_labels, pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Cluster Node\", \"Void Node\"],\n",
    "                yticklabels=[\"Cluster Node\", \"Void Node\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z1htfvtYf-D"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "You have:\n",
    "- Loaded Rockstar halo data from CAMELS\n",
    "- Built a graph of halo interactions\n",
    "- Trained a simple GNN to classify halos by mass\n",
    "- Evaluated and visualized your results\n",
    "\n",
    "Next steps (optional for student):\n",
    "- Improve graph construction (physical cuts, dynamic radius)\n",
    "- Experiment with different GNN layers (GraphSAGE, GAT)\n",
    "- Try regression instead of classification (predict mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUn1NpYKYfvm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnDHJJpo7GYYWDLFXO+tyX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
