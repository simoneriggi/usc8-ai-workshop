{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10df2d01",
   "metadata": {},
   "source": [
    "# First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda7e73",
   "metadata": {},
   "source": [
    "## Module installation\n",
    "Let's first install required python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f608540",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "##   IMGPROC MODULES\n",
    "###########################\n",
    "%pip install -q pillow opencv-python\n",
    "\n",
    "###########################\n",
    "##   ML MODULES\n",
    "###########################\n",
    "%pip install -q torch torchvision torchmetrics torchsummary scikit-learn tqdm\n",
    "%pip install -q wandb -qqq\n",
    "%pip install -q grad-cam\n",
    "\n",
    "###########################\n",
    "##   OTHER MODULES\n",
    "###########################\n",
    "%pip install -q shortuuid\n",
    "%pip install -q gdown # gDrive\n",
    "%pip install -q matplotlib\n",
    "\n",
    "###########################\n",
    "##   LOGGING\n",
    "###########################\n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "# Create the Logger\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(levelname)s - %(message)s\",datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger= logging.getLogger(\"gmnist-classifier\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eab38b",
   "metadata": {},
   "source": [
    "### Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc372736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_dir(dirname):\n",
    "    logger.info(\"Creating directory %s ...\" % (dirname))\n",
    "    path = Path(dirname)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(\"Run directory %s created successfully ...\" % (dirname))\n",
    "\n",
    "# - Set project directory\n",
    "topdir= os.getcwd()\n",
    "logger.info(\"topdir=%s\" % (topdir))\n",
    "\n",
    "############################\n",
    "##   DATASET URL\n",
    "############################\n",
    "dataset_name= \"galaxy_mnist-dataset\"\n",
    "dataset_dir= os.path.join(topdir, dataset_name)\n",
    "dataset_filename= 'galaxy_mnist-dataset.tar.gz'\n",
    "dataset_url= 'https://drive.google.com/uc?export=download&id=1OprJ_NQIFyQSRWqjGLFQsAMumHvJ-tMB'\n",
    "filename_train= os.path.join(dataset_dir, \"train/1chan/datalist_train.json\")\n",
    "filename_test= os.path.join(dataset_dir, \"test/1chan/datalist_test.json\")\n",
    "filename_train_3chan= os.path.join(dataset_dir, \"train/3chan/datalist_train.json\")\n",
    "filename_test_3chan= os.path.join(dataset_dir, \"test/3chan/datalist_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186fc69",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "For this tutorial, we are going to use the Galaxy MNIST dataset [https://github.com/mwalmsley/galaxy_mnist]. We have slighly modified the format for this tutorial. The modified dataset is available for download in Google Drive.\n",
    "\n",
    "The dataset currently contains 10,000 images of galaxies in three optical bands, either low3x64x64 (low reso) or 3x224x224 (high reso), taken from the Galaxy Zoo project. The dataset is split into two subsets: \n",
    "\n",
    "- train: 8000 images\n",
    "- test: 2000 images\n",
    "\n",
    "The dataset contains 4 possible classes of galaxy morphologies:\n",
    "\n",
    "- SMOOTH_ROUND: smooth and round galaxy. Should not have signs of spires.   \n",
    "- SMOOTH_CIGAR: smooth and cigar-shaped galaxy, looks like being seen edge on. This should not have signs of spires of a spiral galaxy.\n",
    "- EDGE_ON_DISK: edge-on-disk/spiral galaxy. This disk galaxy should have signs of spires, as seen from an edge-on perspective.\n",
    "- UNBARRED_SPIRAL: unbarred spiral galaxy. Has signs of a disk and/or spires\n",
    "\n",
    "Note that categories SMOOTH_CIGAR and EDGE_ON_DISK classes tend to be very similar to each other. To categorize them, ask yourself the following question: Is this galaxy very smooth, maybe with a small bulge? Then it belongs to class SMOOTH_CIGAR. Does it have irregularities/signs of structure? Then it belongs to class EDGE_ON_DISK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1140bb1",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "We download the dataset from GoogleDrive and unzip it in the main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import tarfile\n",
    "\n",
    "#################################\n",
    "##      DOWNLOAD FILES\n",
    "#################################\n",
    "def download_files_from_gdrive(url, outfile, force=False):\n",
    "  \"\"\" Download model file from gDrive \"\"\"\n",
    "\n",
    "  if force or not os.path.isfile(outfile):\n",
    "    gdown.download(url, outfile, quiet=False)\n",
    "   \n",
    "def untar_file(filename):\n",
    "  \"\"\" Unzip file \"\"\"\n",
    "  \n",
    "  fp= tarfile.open(filename)\n",
    "  fp.extractall('.')\n",
    "  fp.close()  \n",
    "\n",
    "# - Enter top directory\n",
    "os.chdir(topdir)\n",
    "\n",
    "# - Download dataset\n",
    "logger.info(\"Downloading file from url %s ...\" % (dataset_url))\n",
    "download_files_from_gdrive(dataset_url, dataset_filename, force=False)\n",
    "logger.info(\"DONE!\")\n",
    "\n",
    "# - Untar dataset\n",
    "logger.info(\"Unzipping dataset file %s ...\" % (dataset_filename))\n",
    "untar_file(dataset_filename)\n",
    "logger.info(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82cb76",
   "metadata": {},
   "source": [
    "## Create PyTorch Dataset\n",
    "Let's create a custom pytorch dataset using base VisionDataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151932d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import Subset, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import ToTensor\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from itertools import islice\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#################################\n",
    "##      DATASET\n",
    "#################################\n",
    "class GMNISTDataset(Dataset):\n",
    "  \"\"\" Galaxy MNIST dataset \"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self, \n",
    "      metadata_file: Optional[Union[str, Path]] = \"\",\n",
    "      subset: Optional[Subset] = None,\n",
    "      transform: Optional[Callable] = None,\n",
    "      target_transform: Optional[Callable] = None,\n",
    "  ):\n",
    "    \"\"\"\n",
    "      Arguments:\n",
    "        metadata_file (string): Path to the json file with annotations.\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.subset= subset\n",
    "    if self.subset is None:\n",
    "        logger.info(\"Reading dataset metadata from file %s ...\" % (metadata_file))\n",
    "        self.__read_metadata(metadata_file)\n",
    "        \n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "    self.pil2tensor = T.Compose([T.PILToTensor()]) # no normalization\n",
    "    #self.pil2tensor = T.Compose([T.ToTensor()]) # normalize in [0,1] assuming max=255\n",
    "    \n",
    "    self.target2label= {\n",
    "      0: \"smooth_round\",  \n",
    "      1: \"smooth_cigar\",\n",
    "      2: \"edge_on_disk\",\n",
    "      3: \"unbarred_spiral\"\n",
    "    }\n",
    "\n",
    "  def __read_metadata(self, filename):\n",
    "    \"\"\" Read json metadata \"\"\"\n",
    "    \n",
    "    f= open(filename, \"r\")\n",
    "    self.datalist= json.load(f)[\"data\"]\n",
    "  \n",
    "  def __len__(self):\n",
    "    \"\"\" Return size of dataset \"\"\" \n",
    "    if self.subset:\n",
    "      return len(self.subset) \n",
    "    else:\n",
    "      return len(self.datalist)\n",
    "   \n",
    "  def __load_item(self, idx):\n",
    "    \"\"\" Load dataset item \"\"\"\n",
    "    \n",
    "    # - Read image path & class id\n",
    "    img_path= self.datalist[idx]['filepaths'][0]\n",
    "    target= self.datalist[idx]['id'] # class id\n",
    "    \n",
    "    # - Read PIL image as RGB\n",
    "    #logger.info(\"Read PIL image ...\")\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    \n",
    "    return img, target\n",
    "    \n",
    "  def __load_subset_item(self, idx):\n",
    "    \"\"\" Load dataset subset item \"\"\"\n",
    "    \n",
    "    # - Get item from subset\n",
    "    #   NB: img is a tensor\n",
    "    #logger.info(\"Read subset item ...\")\n",
    "    return self.subset[idx]\n",
    "\n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\" Return dataset item \"\"\"\n",
    "    \n",
    "    # - Load image/label\n",
    "    if self.subset is None:\n",
    "      img, target= self.__load_item(idx)\n",
    "    else:\n",
    "      img, target= self.subset[idx]\n",
    "\n",
    "    # - Convert PIL to tensor?\n",
    "    if isinstance(img, PIL.Image.Image):\n",
    "      img= self.pil2tensor(img)\n",
    "    \n",
    "    # - Transform img/tensor?\n",
    "    if self.transform is not None:\n",
    "      #logger.info(\"__getitem__: Transform image ...\")\n",
    "      img = self.transform(img)\n",
    "\n",
    "    # - Transform target?\n",
    "    if self.target_transform is not None:\n",
    "      target = self.target_transform(target)\n",
    "       \n",
    "    return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce61db",
   "metadata": {},
   "source": [
    "## Create data custom transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef900720",
   "metadata": {},
   "source": [
    "### Random flip\n",
    "A transform that flip either image horizontally/vertically or leave image unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFlip(torch.nn.Module):\n",
    "  \"\"\" Flip image \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, img):\n",
    "    op= random.choice([1,2,3])\n",
    "    if op==1:\n",
    "      return TF.hflip(img)\n",
    "    elif op==2:\n",
    "      return TF.vflip(img)\n",
    "    else:\n",
    "      return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca19031",
   "metadata": {},
   "source": [
    "### Random rotate\n",
    "A transform that randomly rotate image by 90 degrees step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c450f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotate90(torch.nn.Module):\n",
    "  \"\"\"Rotate by one of the given angles: 90, 270, \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, img):\n",
    "    op= random.choice([1,2,3,4])\n",
    "    if op==1:\n",
    "      return TF.rotate(img, 90)\n",
    "    elif op==2:\n",
    "      return TF.rotate(img, 180)\n",
    "    elif op==3:\n",
    "      return TF.rotate(img, 270)\n",
    "    elif op==4:\n",
    "      return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500014a",
   "metadata": {},
   "source": [
    "### Sanitization\n",
    "A transform that set NaNs/inf pixels to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c77c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sanitization(torch.nn.Module):\n",
    "  \"\"\" Set NaN/inf pixels to 0 \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "   \n",
    "  def forward(self, img):\n",
    "    # - Create mask of non-nans pixels    \n",
    "    cond= np.isfinite(img).bool()  \n",
    "    \n",
    "    # - Set nans to 0\n",
    "    img[~cond]= 0\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed6f10",
   "metadata": {},
   "source": [
    "### MinMax Normalization\n",
    "A transform that normalize each image channel separately to desired range (e.g. [0,1]). Please note that torch\n",
    "ToTensor() transform do [0,1] normalization but it assumes a data maximum of 255. Many image channels in \n",
    "GMNIST dataset have a smaller maximum. This transform treats each channels independently, equalizing channel range. \n",
    "This means ignoring a given flux ratio between bands as a potential image classification feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c97c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxNormalization(torch.nn.Module):\n",
    "  \"\"\" Normalize each tensor in batch in min/max range \"\"\"\n",
    "\n",
    "  def __init__(self, norm_min=0., norm_max=1., exclude_zeros=True, set_nans_to_min=False):\n",
    "    super().__init__()\n",
    "    self.norm_min= norm_min\n",
    "    self.norm_max= norm_max\n",
    "    self.exclude_zeros= exclude_zeros\n",
    "    self.set_nans_to_min= set_nans_to_min\n",
    "    \n",
    "  def forward(self, img):\n",
    "    # - Compute data min/max of each image in batch across ny,nx channels\n",
    "    ndim= img.ndim\n",
    "    if ndim==4: # [BATCH,CHAN,Ny,Nx]\n",
    "      img_min= torch.amin(img, dim=(2,3), keepdim=True)\n",
    "      img_max= torch.amax(img, dim=(2,3), keepdim=True)\n",
    "    elif ndim==3: # [CHAN,Ny,Nx]\n",
    "      img_min= torch.amin(img, dim=(1,2), keepdim=True)\n",
    "      img_max= torch.amax(img, dim=(1,2), keepdim=True)\n",
    "    else:\n",
    "      logger.warn(\"Unexpected ndim (%d), returning same image ...\" % (ndim))\n",
    "      return img\n",
    "        \n",
    "    # - Create mask of non-nans/empty pixels\n",
    "    if self.exclude_zeros:\n",
    "      cond= np.logical_and(img!=0, np.isfinite(img)).bool()\n",
    "    else:\n",
    "      cond= np.isfinite(img).bool()\n",
    "\n",
    "    # - Normalize image in range\n",
    "    img_norm= (img-img_min)/(img_max-img_min) * (self.norm_max-self.norm_min) + self.norm_min\n",
    "\n",
    "    # - Set nans to 0\n",
    "    if self.set_nans_to_min:\n",
    "      img_norm[~cond]= self.norm_min\n",
    "    else:\n",
    "      img_norm[~cond]= 0 \n",
    "    \n",
    "    return img_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63266e3d",
   "metadata": {},
   "source": [
    "### Absolute Channel Maximum Scaling\n",
    "This transform finds, for each image, the absolute maximum, and then it scales all channels by this value, taking into account any possible band flux ratio information as sensitive classification variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsChanMaxScaling(torch.nn.Module):\n",
    "  \"\"\" Scale tensor by absolute channel maximum \"\"\"\n",
    "\n",
    "  def __init__(self):    \n",
    "    super().__init__()\n",
    "   \n",
    "  def forward(self, img):\n",
    "    \n",
    "    # - Compute absolute image max across channels\n",
    "    ndim= img.ndim\n",
    "    if ndim==4: # [BATCH,CHAN,Ny,Nx]\n",
    "      img_absmax= torch.amax(img, dim=(1,2,3), keepdim=True)\n",
    "    elif ndim==3: # [CHAN,Ny,Nx]\n",
    "      img_absmax= torch.amax(img, dim=(0,1,2), keepdim=True)\n",
    "    else:\n",
    "      logger.warn(\"Unexpected ndim (%d), returning same image ...\" % (ndim))\n",
    "      return img\n",
    "    \n",
    "    # - Scale image by absmax\n",
    "    img_scaled= img/img_absmax\n",
    "    \n",
    "    return img_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40348d7",
   "metadata": {},
   "source": [
    "### Define composite transforms\n",
    "Let's define two transforms: one for training data, having standard plus additional augmenter transforms, and the other for validation/test data, having standard transforms.\n",
    "\n",
    "Standard transforms are:\n",
    "\n",
    "- Sanitization\n",
    "- Image resize\n",
    "- Intra-channel normalization\n",
    "- Image sample normalization (optional)\n",
    "\n",
    "Augmenter transforms are:\n",
    "\n",
    "- Random flipping\n",
    "- Random rotation 90 deg\n",
    "- Random crop and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Define dataset transforms\n",
    "logger.info(\"Define dataset transforms ...\")\n",
    "img_resize= 224\n",
    "\n",
    "transform_train= T.Compose(\n",
    "  [  \n",
    "    Sanitization(),  \n",
    "    T.Resize(img_resize, interpolation=T.InterpolationMode.BICUBIC),\n",
    "    RandomFlip(),\n",
    "    RandomRotate90(),\n",
    "    T.RandomResizedCrop(img_resize, scale=(0.5, 1.0), ratio=(1., 1.), interpolation=T.InterpolationMode.BICUBIC),\n",
    "    AbsChanMaxScaling(),  \n",
    "    #T.ToTensor(),# convert to tensor in range [0,1]\n",
    "  ]\n",
    ")\n",
    "\n",
    "transform_imagenet_train= T.Compose(\n",
    "  [  \n",
    "    Sanitization(),  \n",
    "    T.Resize(img_resize, interpolation=T.InterpolationMode.BICUBIC),\n",
    "    RandomFlip(),\n",
    "    RandomRotate90(),\n",
    "    T.RandomResizedCrop(img_resize, scale=(0.5, 1.0), ratio=(1., 1.), interpolation=T.InterpolationMode.BICUBIC),\n",
    "    AbsChanMaxScaling(),  \n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  \n",
    "  ]\n",
    ")\n",
    "\n",
    "transform= T.Compose(\n",
    "  [\n",
    "    Sanitization(),  \n",
    "    T.Resize(img_resize, interpolation=T.InterpolationMode.BICUBIC),\n",
    "    AbsChanMaxScaling()\n",
    "  ]\n",
    ")\n",
    "\n",
    "transform_imagenet= T.Compose(\n",
    "  [\n",
    "    Sanitization(),  \n",
    "    T.Resize(img_resize, interpolation=T.InterpolationMode.BICUBIC),\n",
    "    AbsChanMaxScaling(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))   \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa5fa3",
   "metadata": {},
   "source": [
    "## Create datasets\n",
    "Load GMNIST train/test dataset using the GMNISTDataset class created above. Then, split the train dataset into two subsets, one to be used as training set (70% of the original train sample) and the other as validation set (the remaining 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Read traincv dataset\n",
    "logger.info(\"Read train-cv dataset from file %s ...\" % (filename_train_3chan))\n",
    "dataset_traincv= GMNISTDataset(\n",
    "  metadata_file=filename_train_3chan,\n",
    ")\n",
    "\n",
    "# - Read test dataset\n",
    "logger.info(\"Read test dataset from file %s ...\" % (filename_test_3chan))\n",
    "dataset_test= GMNISTDataset(\n",
    "  metadata_file=filename_test_3chan,\n",
    "  transform=transform\n",
    ")\n",
    "dataset_imagenet_test= GMNISTDataset(\n",
    "  metadata_file=filename_test_3chan,\n",
    "  transform=transform_imagenet\n",
    ")\n",
    "\n",
    "# - Split train-cv dataset into train & validation samples\n",
    "logger.info(\"Splitting train-cv dataset in 70% train/30% val subsets...\")\n",
    "generator= torch.Generator().manual_seed(42)\n",
    "subset_train, subset_val= random_split(dataset_traincv, [0.7, 0.3], generator=generator)\n",
    "\n",
    "# - Create train & val datasets from subsets\n",
    "logger.info(\"Creating train & val datasets from subsets ...\")\n",
    "dataset_train= GMNISTDataset(subset=subset_train, transform=transform_train)\n",
    "dataset_imagenet_train= GMNISTDataset(subset=subset_train, transform=transform_imagenet_train)\n",
    "dataset_val= GMNISTDataset(subset=subset_val, transform=transform)\n",
    "dataset_imagenet_val= GMNISTDataset(subset=subset_val, transform=transform_imagenet)\n",
    "\n",
    "logger.info(\"#%d entries in train set ...\" % (len(dataset_train)))\n",
    "logger.info(\"#%d entries in validation set ...\" % (len(dataset_val)))\n",
    "logger.info(\"#%d entries in test set ...\" % (len(dataset_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9465ef",
   "metadata": {},
   "source": [
    "### Draw sample images\n",
    "Let's draw some sample images from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605827ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Plot images\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i, (tensor_image, target) in islice(enumerate(dataset_train), 16):\n",
    "  label= dataset_train.target2label[target]  \n",
    "  ax = fig.add_subplot(4, 4, i+1)\n",
    "  ax.set_xticks([]); ax.set_yticks([])\n",
    "  im= ax.imshow(tensor_image.permute(1, 2, 0))\n",
    "  ax.set_title(f'{label}', size=15)\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37b099",
   "metadata": {},
   "source": [
    "# CNN classifier\n",
    "Let's now define a custom configurable CNN architecture to perform GMNIST image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317ea91",
   "metadata": {},
   "source": [
    "## Classifier class\n",
    "Let's implement a class that uses the torch sequential class to define the architecture of the net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from pytorch_grad_cam import (\n",
    "  GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "  AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "  LayerCAM, FullGrad, GradCAMElementWise, KPCA_CAM\n",
    ")\n",
    "from pytorch_grad_cam.utils.find_layers import find_layer_types_recursive\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "\n",
    "class AverageMeter:\n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(self, value, n=1):\n",
    "    self.sum += value * n\n",
    "    self.count += n\n",
    "\n",
    "  @property\n",
    "  def avg(self):\n",
    "    return self.sum / self.count if self.count > 0 else 0\n",
    "\n",
    "###############################\n",
    "##   CLASSIFIER\n",
    "###############################\n",
    "class GMNISTClassifier():\n",
    "  \"\"\" Build a custom CNN network \"\"\"  \n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      nn_arch: Optional[str] = \"custom\",\n",
    "      pretrained_weights: Optional[str] = None,\n",
    "      num_classes: Optional[int] = 4,\n",
    "      n_conv_layers: Optional[int] = 3,\n",
    "      n_filters: Optional[Union[int, list]] = [8,16,32],\n",
    "      kern_sizes: Optional[Union[int, list]] = [3,5,5],\n",
    "      strides: Optional[Union[int, list]] = [1,1,1],\n",
    "      add_maxpool: Optional[bool] = True,\n",
    "      pool_sizes: Optional[Union[int, list]] = 2,\n",
    "      add_batchnorm: Optional[bool] = True,\n",
    "      n_dense_layers: Optional[int] = 1,\n",
    "      dense_layer_sizes: Optional[Union[int, list]] = [64],\n",
    "      add_dropout: Optional[bool] = True,\n",
    "      dropout_prob: Optional[float] = 0.5\n",
    "  ):\n",
    "    #super(GMNISTClassifier, self).__init__()\n",
    "    self.model= None\n",
    "    self.device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.nn_arch= nn_arch\n",
    "    self.num_classes= num_classes\n",
    "    self.n_conv_layers= n_conv_layers\n",
    "    self.n_dense_layers= n_dense_layers\n",
    "    self.add_maxpool= add_maxpool\n",
    "    self.add_batchnorm= add_batchnorm\n",
    "    self.add_dropout= add_dropout\n",
    "    self.dropout_prob= dropout_prob\n",
    "    \n",
    "    # - Set number of conv filters per layer\n",
    "    if isinstance(n_filters, list):\n",
    "      if len(n_filters)!=self.n_conv_layers:\n",
    "        raise Exception(\"n_filters list must have length equal to n_conv_layers!\")  \n",
    "      else:\n",
    "        self.n_filters= n_filters\n",
    "    else:\n",
    "      self.n_filters= [n_filters]*self.n_conv_layers \n",
    "    \n",
    "    # - Set conv filter kernel size per layer\n",
    "    if isinstance(kern_sizes, list):\n",
    "      if len(kern_sizes)!=self.n_conv_layers:\n",
    "        raise Exception(\"kern_sizes list must have length equal to n_conv_layers!\")  \n",
    "      else:\n",
    "        self.kern_sizes= kern_sizes\n",
    "    else:\n",
    "      self.kern_sizes= [kern_sizes]*self.n_conv_layers\n",
    "    \n",
    "    # - Set conv filter stride size per layer\n",
    "    if isinstance(strides, list):\n",
    "      if len(strides)!=self.n_conv_layers:\n",
    "        raise Exception(\"strides list must have length equal to n_conv_layers!\")  \n",
    "      else:\n",
    "        self.strides= strides\n",
    "    else:\n",
    "      self.strides= [strides]*self.n_conv_layers\n",
    "    \n",
    "    # - Set conv filter stride size per layer\n",
    "    if isinstance(pool_sizes, list):\n",
    "      if len(pool_sizes)!=self.n_conv_layers:\n",
    "        raise Exception(\"pool_sizes list must have length equal to n_conv_layers!\")  \n",
    "      else:\n",
    "        self.pool_sizes= pool_sizes\n",
    "    else:\n",
    "      self.pool_sizes= [pool_sizes]*self.n_conv_layers\n",
    "    \n",
    "    # - Set dense layer size per layer\n",
    "    if isinstance(dense_layer_sizes, list):\n",
    "      if len(dense_layer_sizes)!=self.n_dense_layers:\n",
    "        raise Exception(\"pool_sizes list must have length equal to n_conv_layers!\")  \n",
    "      else:\n",
    "        self.dense_layer_sizes= dense_layer_sizes\n",
    "    else:\n",
    "      self.dense_layer_sizes= [dense_layer_sizes]*self.n_dense_layers\n",
    "    \n",
    "    # - Build network\n",
    "    logger.info(\"Building NN architecture ...\")\n",
    "    if self.__build_net(pretrained_weights)<0:\n",
    "      logger.error(\"Failed to build nn!\")\n",
    "      raise Exception(\"Failed to build nn!\")\n",
    "    \n",
    "    # - Move model to device\n",
    "    logger.info(\"Moving model to device %s ...\" % (self.device))\n",
    "    self.model.to(self.device)\n",
    "    \n",
    "\n",
    "  def __build_net(self, pretrained_weights=None):\n",
    "    \"\"\" Create network from pre-defined architecture (e.g. resnet) \"\"\"\n",
    "    \n",
    "    if self.nn_arch==\"custom\":\n",
    "      logger.info(\"Initializing network with custom architecture ...\")\n",
    "      return self.__build_custom_net()\n",
    "    else:\n",
    "      logger.info(\"Initializing network with %s architecture ...\" % (self.nn_arch))\n",
    "      return self.__build_predefined_net(pretrained_weights)\n",
    "\n",
    "  def __build_predefined_net(self, pretrained_weights=None):\n",
    "    \"\"\" Create network from pre-defined architecture (e.g. resnet) \"\"\"\n",
    "    \n",
    "    # - Load predefined arch\n",
    "    if self.nn_arch==\"resnet18\":\n",
    "      # Pretrained weights are: 'IMAGENET1K_V1'\n",
    "      self.model = torchvision.models.resnet18(weights=pretrained_weights) \n",
    "    elif self.nn_arch==\"resnet34\":\n",
    "      # Pretrained weights are: 'IMAGENET1K_V1'  \n",
    "      self.model = torchvision.models.resnet34(weights=pretrained_weights)  \n",
    "    elif self.nn_arch==\"resnet50\":\n",
    "      # Pretrained weights are: {'IMAGENET1K_V1','IMAGENET1K_V2'}\n",
    "      self.model = torchvision.models.resnet50(weights=pretrained_weights)\n",
    "    elif self.nn_arch==\"resnet101\":\n",
    "      # Pretrained weights are: {'IMAGENET1K_V1','IMAGENET1K_V2'}  \n",
    "      self.model = torchvision.models.resnet101(weights=pretrained_weights)\n",
    "    else:\n",
    "      logger.error(\"Unsupported nn arch (%s) specified, see torch supported arch below and add it yourself!\")\n",
    "      print(torchvision.models.list_models(module=torchvision.models)) \n",
    "      return -1\n",
    "\n",
    "    # - Define classification head\n",
    "    class_head= torch.nn.Sequential()\n",
    "    \n",
    "    for i in range(self.n_dense_layers):\n",
    "      # - Add dense layer\n",
    "      layer_name= \"fc\" + str(i+1)\n",
    "      class_head.add_module(layer_name, torch.nn.LazyLinear(self.dense_layer_sizes[i]))\n",
    "    \n",
    "      # - Add activation\n",
    "      layer_name= \"relu_fc\" + str(i+1)  \n",
    "      class_head.add_module(layer_name, torch.nn.ReLU())\n",
    "    \n",
    "      # - Add dropout?\n",
    "      if self.add_dropout:\n",
    "        layer_name= \"dropout\" + str(i+1)  \n",
    "        class_head.add_module(layer_name, torch.nn.Dropout(p=self.dropout_prob))\n",
    "    \n",
    "    # - Add dropout if no dense layer specified?\n",
    "    if self.n_dense_layers<=0 and self.add_dropout:\n",
    "      class_head.add_module(\"dropout\", torch.nn.Dropout(p=self.dropout_prob))  \n",
    "    \n",
    "    # - Add output layer\n",
    "    class_head.add_module(\"output\", torch.nn.LazyLinear(self.num_classes))\n",
    "    \n",
    "    # - Override head\n",
    "    self.model.fc = class_head\n",
    "    \n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    \n",
    "  def __build_custom_net(self):  \n",
    "    \"\"\" Create network \"\"\"\n",
    "    \n",
    "    # - Create model using nn.Sequential class\n",
    "    self.model = torch.nn.Sequential()\n",
    "    \n",
    "    # - Add CNN layers\n",
    "    for i in range(self.n_conv_layers):\n",
    "      # - Add convolution layer  \n",
    "      layer_name= 'conv' + str(i+1)\n",
    "      #in_channels= 3 if i==0 else self.n_conv_filters[i-1]\n",
    "      \n",
    "      self.model.add_module(\n",
    "        layer_name,\n",
    "        torch.nn.LazyConv2d(\n",
    "          #in_channels=in_channels, \n",
    "          out_channels=self.n_filters[i],\n",
    "          kernel_size=self.kern_sizes[i],\n",
    "          padding=\"same\",\n",
    "          stride=self.strides[i]\n",
    "        )\n",
    "      )\n",
    "    \n",
    "      # - Add activation\n",
    "      layer_name= 'relu' + str(i+1)\n",
    "      self.model.add_module(layer_name, torch.nn.ReLU())\n",
    "      \n",
    "      # - Add batch normalization?\n",
    "      if self.add_batchnorm:\n",
    "        layer_name= \"bn\" + str(i+1)\n",
    "        self.model.add_module(layer_name, torch.nn.LazyBatchNorm2d())\n",
    "    \n",
    "      # - Add max pool layer?\n",
    "      if self.add_maxpool:\n",
    "        layer_name= 'pool' + str(i+1)\n",
    "        self.model.add_module(layer_name, torch.nn.MaxPool2d(kernel_size=self.pool_sizes[i]))\n",
    "        \n",
    "    # - Flatten layer\n",
    "    self.model.add_module('flatten', torch.nn.Flatten())\n",
    "    \n",
    "    # - Add dense layers\n",
    "    for i in range(self.n_dense_layers):\n",
    "      # - Add dense layer\n",
    "      layer_name= \"fc\" + str(i+1)\n",
    "      self.model.add_module(layer_name, torch.nn.LazyLinear(self.dense_layer_sizes[i]))\n",
    "    \n",
    "      # - Add activation\n",
    "      layer_name= \"relu_fc\" + str(i+1)  \n",
    "      self.model.add_module(layer_name, torch.nn.ReLU())\n",
    "    \n",
    "      # - Add dropout?\n",
    "      if self.add_dropout:\n",
    "        layer_name= \"dropout\" + str(i+1)  \n",
    "        self.model.add_module(layer_name, torch.nn.Dropout(p=self.dropout_prob))\n",
    "    \n",
    "    # - Add dropout if no dense layer specified?\n",
    "    if self.n_dense_layers<=0 and self.add_dropout:\n",
    "      self.model.add_module(\"dropout\", torch.nn.Dropout(p=self.dropout_prob))  \n",
    "    \n",
    "    # - Add output layer\n",
    "    self.model.add_module(\"output\", torch.nn.LazyLinear(self.num_classes))\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "  def print_model_arch(self, input_shape):\n",
    "    \"\"\" Print model arch summary \"\"\"\n",
    "    summary(self.model, input_shape)\n",
    "\n",
    "  def __train_epoch(\n",
    "    self,\n",
    "    dataloader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    epoch, \n",
    "    accuracy_metric,\n",
    "    f1score_metric\n",
    "  ):\n",
    "    \"\"\" Train one epoch \"\"\"\n",
    "    \n",
    "    # - Init metrics\n",
    "    self.model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_metric.reset()\n",
    "    f1score_metric.reset()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Training]\", leave=False)\n",
    "\n",
    "    # - Run batch loop\n",
    "    for X_batch, y_batch in progress_bar:\n",
    "      X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "      # - Compute prediction and loss   \n",
    "      outputs = self.model(X_batch)\n",
    "      loss = criterion(outputs, y_batch)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # - Update loss and accuracy\n",
    "      loss_meter.update(loss.item(), X_batch.size(0))\n",
    "      preds = outputs.argmax(dim=1)\n",
    "      accuracy_metric.update(preds, y_batch)\n",
    "      f1score_metric.update(preds, y_batch)\n",
    "\n",
    "      # - Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "        loss=loss_meter.avg, \n",
    "        accuracy=accuracy_metric.compute().item(),\n",
    "        f1score=f1score_metric.compute().item()\n",
    "      )\n",
    "\n",
    "    avg_loss = loss_meter.avg\n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    avg_f1score = f1score_metric.compute().item()\n",
    "\n",
    "    return avg_loss, avg_accuracy, avg_f1score\n",
    "\n",
    "  def __validate_epoch(\n",
    "    self,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    epoch,\n",
    "    accuracy_metric,\n",
    "    f1score_metric  \n",
    "  ):\n",
    "    \"\"\" Run validation loop \"\"\"      \n",
    "    \n",
    "    # - Init metrics\n",
    "    self.model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_metric.reset()\n",
    "    f1score_metric.reset()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Validation]\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for X_batch, y_batch in progress_bar:\n",
    "        X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "        # - Compute prediction and loss   \n",
    "        outputs = self.model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # - Update loss and accuracy\n",
    "        loss_meter.update(loss.item(), X_batch.size(0))\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracy_metric.update(preds, y_batch)\n",
    "        f1score_metric.update(preds, y_batch)\n",
    "\n",
    "        # - Update progress bar\n",
    "        progress_bar.set_postfix(\n",
    "          loss=loss_meter.avg\n",
    "        )\n",
    "        \n",
    "    avg_loss = loss_meter.avg\n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    avg_f1score = f1score_metric.compute().item()\n",
    "    \n",
    "    return avg_loss, avg_accuracy, avg_f1score\n",
    "    \n",
    "    \n",
    "  def run_train(\n",
    "    self,\n",
    "    train_dl,\n",
    "    val_dl= None,\n",
    "    num_epochs: Optional[int] = 1, \n",
    "    lr: Optional[float] = 1e-4,\n",
    "    log_to_wandb=False,\n",
    "    outfile_prefix=\"model\"\n",
    "  ):\n",
    "    \"\"\" Train network \"\"\"\n",
    "\n",
    "    # - Check model was created\n",
    "    if self.model is None:\n",
    "      logger.error(\"Model was not initialized!\")\n",
    "      return -1\n",
    "\n",
    "    # - Set loss\n",
    "    logger.info(\"Defining loss & optimizer ...\")\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "    \n",
    "    # - Init metrics\n",
    "    train_accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes).to(self.device)\n",
    "    train_f1score_metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes, average=\"macro\").to(self.device)\n",
    "    val_accuracy = None\n",
    "    val_f1score = None\n",
    "    if val_dl is not None:\n",
    "      val_accuracy_metric= torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes).to(self.device)\n",
    "      val_f1score_metric= torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes, average=\"macro\").to(self.device)\n",
    "\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    f1score_hist_train = [0] * num_epochs\n",
    "    loss_hist_val = [0] * num_epochs\n",
    "    accuracy_hist_val = [0] * num_epochs\n",
    "    f1score_hist_val = [0] * num_epochs \n",
    "        \n",
    "    # - Training loop\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "      # - Run train batch loop\n",
    "      train_loss, train_acc, train_f1score = self.__train_epoch(\n",
    "        train_dl, \n",
    "        loss_fn, \n",
    "        optimizer,\n",
    "        epoch, \n",
    "        train_accuracy_metric,\n",
    "        train_f1score_metric  \n",
    "      )\n",
    "      loss_hist_train[epoch]= train_loss\n",
    "      accuracy_hist_train[epoch]= train_acc\n",
    "      f1score_hist_train[epoch]= train_f1score\n",
    "        \n",
    "      # - Run validation batch loop?\n",
    "      val_loss= 0.\n",
    "      val_acc= 0.\n",
    "      val_f1score= 0.\n",
    "        \n",
    "      if val_dl is not None:\n",
    "        val_loss, val_acc, val_f1score = self.__validate_epoch(\n",
    "          val_dl, \n",
    "          loss_fn,\n",
    "          epoch, \n",
    "          val_accuracy_metric,\n",
    "          val_f1score_metric  \n",
    "        )\n",
    "        loss_hist_val[epoch]= val_loss\n",
    "        accuracy_hist_val[epoch]= val_acc\n",
    "        f1score_hist_val[epoch]= val_f1score\n",
    "\n",
    "      # - Log metrics to wandb \n",
    "      if log_to_wandb:\n",
    "        wandb.log(\n",
    "          {\n",
    "            \"loss\": train_loss,  \n",
    "            \"acc\": train_acc,\n",
    "            \"f1score\": train_f1score,  \n",
    "            \"loss_val\": val_loss,  \n",
    "            \"acc_val\": val_acc,\n",
    "            \"f1score_val\": val_f1score, \n",
    "          }\n",
    "        )\n",
    "        \n",
    "      # - Print metrics  \n",
    "      if val_dl is not None:\n",
    "        logger.info(\"Epoch [%d/%d]: loss=%.4f (val=%.4f), acc=%.4f (val=%.4f), f1=%.4f (val=%.4f)\" % (epoch, num_epochs, train_loss, val_loss, train_acc, val_acc, train_f1score, val_f1score))\n",
    "      else:\n",
    "        logger.info(\"Epoch [%d/%d]: loss=%.4f, acc=%.4f, f1=%.4f\" % (epoch, num_epochs, train_loss, train_acc, train_f1score))\n",
    "        \n",
    "      # - Save best model  \n",
    "      if val_dl is not None and val_acc > best_val_acc:  \n",
    "        best_val_acc = val_acc\n",
    "        logger.info(\"Saving best model at epoch %d (acc_val=%.4f) ...\" % (epoch+1, best_val_acc))  \n",
    "        torch.save(self.model.state_dict(), outfile_prefix + \"_weights_best.pth\")  \n",
    "        torch.save(self.model, outfile_prefix + \"_best.pth\")\n",
    "          \n",
    "    # - Save final model\n",
    "    logger.info(\"Saving final model ...\")  \n",
    "    torch.save(self.model.state_dict(), outfile_prefix + \"_weights.pth\")\n",
    "    torch.save(self.model, outfile_prefix + \".pth\")\n",
    "    \n",
    "    # - Set metric history\n",
    "    metric_hist= {\n",
    "      \"loss_train\": loss_hist_train,\n",
    "      \"acc_train\": accuracy_hist_train,\n",
    "      \"f1score_train\": f1score_hist_train,\n",
    "      \"loss_val\": loss_hist_val,\n",
    "      \"acc_val\": accuracy_hist_val,\n",
    "      \"f1score_val\": f1score_hist_val\n",
    "    }\n",
    "    \n",
    "    logger.info(\"END TRAIN RUN\")\n",
    "    \n",
    "    return metric_hist\n",
    "\n",
    "  def run_test(self, dataloader, modelfile=\"\", weightfile=\"\"):\n",
    "    \"\"\" Compute model performances on test data \"\"\"\n",
    "    \n",
    "    # - Load model from file?\n",
    "    if modelfile==\"\":\n",
    "      model= self.model  \n",
    "    else:\n",
    "      logger.info(\"Loading model from file %s ...\" % (modelfile))    \n",
    "      model= torch.load(modelfile, weights_only=False)\n",
    "      \n",
    "    # - Check for model/dataloader\n",
    "    if self.model is None:\n",
    "      logger.error(\"No model present, cannot run prediction on test set!\")\n",
    "      return None\n",
    "    \n",
    "    # - Load model weights\n",
    "    if weightfile!=\"\":\n",
    "      logger.info(\"Loading model weights from file %s ...\" % (weightfile))\n",
    "      model.load_state_dict(torch.load(weightfile, weights_only=True))\n",
    "    \n",
    "    model.to(self.device).eval()\n",
    "    \n",
    "    # - Init metrics    \n",
    "    accuracy_metric= torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes).to(self.device)\n",
    "    accuracy_metric.reset()\n",
    "    f1score_metric= torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes, average=\"macro\").to(self.device)\n",
    "    f1score_metric.reset()\n",
    "    confusion_matrix_metric= torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=self.num_classes, normalize=\"true\").to(self.device)\n",
    "    confusion_matrix_metric.reset()\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"[Test]\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for X_batch, y_batch in progress_bar:\n",
    "        X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "        # - Compute prediction and loss   \n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # - Update loss and accuracy\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracy_metric.update(preds, y_batch)\n",
    "        f1score_metric.update(preds, y_batch)\n",
    "        confusion_matrix_metric.update(preds, y_batch)\n",
    "        \n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    avg_f1score = f1score_metric.compute().item()\n",
    "    confusion_matrix= confusion_matrix_metric.compute().numpy()\n",
    "    #confusion_matrix= confusion_matrix_metric.compute()\n",
    "    \n",
    "    metrics= {\n",
    "      \"acc\": avg_accuracy,\n",
    "      \"avg_f1score\": avg_f1score,\n",
    "      \"cm\": confusion_matrix,\n",
    "      \"cm_metric\": confusion_matrix_metric \n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "  def plot_sample_predictions(self, \n",
    "    dataset,\n",
    "    dataset_gradcam=None,\n",
    "    modelfile=\"\", \n",
    "    weightfile=\"\",\n",
    "    plot_gradcam=True, \n",
    "    gradcam_method=\"gradcam\",\n",
    "    layer_names=[],   \n",
    "    aug_smooth=False,\n",
    "    eigen_smooth=False,\n",
    "    gradcam_alpha=0.5,\n",
    "    apply_heatmap_thr=False,\n",
    "    heatmap_thr=0.7,\n",
    "    plot_gradcam_only=False\n",
    "  ):\n",
    "    \"\"\" Plot gradCAM on some images \"\"\"\n",
    "    \n",
    "    # - Load model from file?\n",
    "    if modelfile==\"\":\n",
    "      model= self.model  \n",
    "    else:\n",
    "      logger.info(\"Loading model from file %s ...\" % (modelfile))    \n",
    "      model= torch.load(modelfile, weights_only=False)\n",
    "      \n",
    "    # - Check for model/dataloader\n",
    "    if self.model is None:\n",
    "      logger.error(\"No model present, cannot run prediction on test set!\")\n",
    "      return None\n",
    "    \n",
    "    # - Load model weights\n",
    "    if weightfile!=\"\":\n",
    "      logger.info(\"Loading model weights from file %s ...\" % (weightfile))\n",
    "      model.load_state_dict(torch.load(weightfile, weights_only=True))\n",
    "    \n",
    "    model.to(self.device).eval()\n",
    "    \n",
    "    # - Set dataset to be used for gradcam\n",
    "    if dataset_gradcam is None:\n",
    "      dataset_gradcam= dataset\n",
    "    \n",
    "    # - Init gradCAM \n",
    "    methods = {\n",
    "      \"gradcam\": GradCAM,\n",
    "      \"hirescam\": HiResCAM,\n",
    "      \"scorecam\": ScoreCAM,\n",
    "      \"gradcam++\": GradCAMPlusPlus,\n",
    "      \"ablationcam\": AblationCAM,\n",
    "      \"xgradcam\": XGradCAM,\n",
    "      \"eigencam\": EigenCAM,\n",
    "      \"eigengradcam\": EigenGradCAM,\n",
    "      \"layercam\": LayerCAM,\n",
    "      \"fullgrad\": FullGrad,\n",
    "      #\"fem\": FEM,\n",
    "      \"gradcamelementwise\": GradCAMElementWise,\n",
    "      \"kpcacam\": KPCA_CAM,\n",
    "      #\"shapleycam\": ShapleyCAM\n",
    "    }\n",
    "    cam_algorithm = methods[gradcam_method]\n",
    "    \n",
    "    logger.info(\"Printing all relu layers in model ...\")\n",
    "    print(model)\n",
    "    print(find_layer_types_recursive(model, [torch.nn.ReLU]))\n",
    "    target_layers= []\n",
    "    for item in layer_names:\n",
    "      layer= model._modules[item]\n",
    "      print(\"layer\")\n",
    "      print(layer)\n",
    "      target_layers.append(layer)\n",
    "    \n",
    "    #target_layers = [model.layer4]\n",
    "    # We have to specify the target we want to generate\n",
    "    # the Class Activation Maps for.\n",
    "    # If targets is None, the highest scoring category (for every member in the batch) will be used.\n",
    "    # You can target specific categories by\n",
    "    # targets = [ClassifierOutputTarget(281)]\n",
    "    # targets = [ClassifierOutputReST(281)]\n",
    "    targets = None\n",
    "    \n",
    "    # - Plot images\n",
    "    # Using the with statement ensures the context is freed, and you can\n",
    "    # recreate different CAM objects in a loop.\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    \n",
    "    #for i, (input_img, target) in islice(enumerate(dataset), 16):\n",
    "    for i, ((input_img, target), (input_img_gradcam, target_gradcam)) in islice(enumerate(zip(dataset,dataset_gradcam)), 16):    \n",
    "      with torch.enable_grad():\n",
    "        # - Compute model prediction\n",
    "        label= dataset.target2label[target] \n",
    "        logger.info(\"Computing model prediction for image (label=%s, target=%d) ...\" % (label, target))\n",
    "        input_tensor= input_img.unsqueeze(0)\n",
    "        input_tensor_gradcam= input_img_gradcam.unsqueeze(0)                                                       \n",
    "          \n",
    "        pred = model(input_tensor) # logits  \n",
    "        y_pred = torch.argmax(pred).item()\n",
    "        soft_outputs = torch.nn.functional.softmax(pred, dim=1) # pass through softmax\n",
    "        prob_pred, target_pred = soft_outputs.topk(1, dim = 1) # select top probability as prediction\n",
    "        prob_pred= prob_pred.item()\n",
    "        target_pred= target_pred.item()  \n",
    "        #label_pred= dataset.target2label[y_pred]\n",
    "        label_pred= dataset.target2label[target_pred]\n",
    "        \n",
    "        # - Create image for plot\n",
    "        #rgb_img= input_img.permute(1, 2, 0).numpy()\n",
    "        rgb_img= input_img_gradcam.permute(1, 2, 0).numpy()                                                       \n",
    "        grayscale_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2GRAY)\n",
    "        #print(\"grayscale_img.shape\")\n",
    "        #print(grayscale_img.shape)\n",
    "        #print(grayscale_img.max())\n",
    "        \n",
    "        # - Compute cam\n",
    "        if plot_gradcam:\n",
    "          with cam_algorithm(model=model, target_layers=target_layers) as cam:\n",
    "            \n",
    "            grayscale_cam = cam(\n",
    "              input_tensor=input_tensor_gradcam, \n",
    "              targets=targets,\n",
    "              aug_smooth=aug_smooth,\n",
    "              eigen_smooth=eigen_smooth\n",
    "            )\n",
    "            #print(\"grayscale_cam.shape\")\n",
    "            #print(grayscale_cam.shape)\n",
    "            grayscale_cam = grayscale_cam[0, :]\n",
    "            #print(grayscale_cam.shape)  \n",
    "        \n",
    "            cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True, image_weight=gradcam_alpha)\n",
    "            cam_image = cv2.cvtColor(cam_image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "            # - Create heatmap\n",
    "            colormap= cv2.COLORMAP_JET\n",
    "            mask= np.copy(grayscale_cam)\n",
    "            heatmap= cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
    "            heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "            heatmap = np.float32(heatmap) / 255\n",
    "            \n",
    "            alphas= np.ones(grayscale_img.shape)*gradcam_alpha\n",
    "            if apply_heatmap_thr:\n",
    "              alphas[grayscale_cam<heatmap_thr]= 0 # set invisible    \n",
    "    \n",
    "        # - Plot image\n",
    "        ax = fig.add_subplot(4, 4, i+1)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        if not plot_gradcam_only:\n",
    "          ax.imshow(grayscale_img, cmap=\"gray\")\n",
    "            \n",
    "        if plot_gradcam:\n",
    "          if plot_gradcam_only:\n",
    "            ax.imshow(cam_image)  \n",
    "          else:\n",
    "            #ax.imshow(heatmap, alpha=gradcam_alpha)\n",
    "            ax.imshow(heatmap, alpha=alphas)\n",
    "            \n",
    "        ax.set_title(f'{label} \\n pred: {label_pred}, p={prob_pred:.1f})', size=12)\n",
    "  \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "  def extract_feature_maps(\n",
    "    self,\n",
    "    image,  \n",
    "    modelfile=\"\", \n",
    "    weightfile=\"\"  \n",
    "  ):\n",
    "    \"\"\" Extract a list of feature map for a model and input image \"\"\"\n",
    "    \n",
    "    # - Load image on device\n",
    "    #   NB: Transforms are expected to be already applied\n",
    "    if image is None:\n",
    "      logger.error(\"Input image is None!\")\n",
    "      return -1\n",
    "    image = image.to(self.device)\n",
    "    \n",
    "    # - Load model from file?\n",
    "    if modelfile==\"\":\n",
    "      model= self.model  \n",
    "    else:\n",
    "      logger.info(\"Loading model from file %s ...\" % (modelfile))    \n",
    "      model= torch.load(modelfile, weights_only=False)\n",
    "      \n",
    "    # - Check for model/dataloader\n",
    "    if self.model is None:\n",
    "      logger.error(\"No model present, cannot run prediction on test set!\")\n",
    "      return None\n",
    "    \n",
    "    # - Load model weights\n",
    "    if weightfile!=\"\":\n",
    "      logger.info(\"Loading model weights from file %s ...\" % (weightfile))\n",
    "      model.load_state_dict(torch.load(weightfile, weights_only=True))\n",
    "    \n",
    "    model.to(self.device).eval()\n",
    "    \n",
    "    # - Extract conv layers\n",
    "    logger.info(\"Extracting all model conv layers ...\")\n",
    "    #conv_layers= self.__extract_conv_layers(model)\n",
    "    conv_layers= []\n",
    "    conv_layer_names= []\n",
    "    for name, layer in model.named_modules():\n",
    "      if type(layer) == torch.nn.Conv2d and \"downsample\" not in name:\n",
    "        conv_layers.append(layer)\n",
    "        conv_layer_names.append(name)\n",
    "     \n",
    "    \n",
    "    # - Extracting feature maps\n",
    "    logger.info(\"Extracting feature maps ...\")\n",
    "    layer_outputs = []\n",
    "    layer_names = []\n",
    "    layer_output= image\n",
    "    for layer, layer_name in zip(conv_layers[0:], conv_layer_names[0:]):\n",
    "      #layer_name= str(layer)\n",
    "      print(\"layer_name\")\n",
    "      print(layer_name)\n",
    "      print(layer)\n",
    "      layer_output= layer(layer_output)\n",
    "      layer_outputs.append(layer_output)\n",
    "      layer_names.append(layer_name)\n",
    "\n",
    "    print(len(layer_outputs))\n",
    "    print(\"--> layer_outputs.shape\")\n",
    "    for layer_output in layer_outputs:\n",
    "      print(layer_output.shape)\n",
    "    \n",
    "    # - Convert 3D tensor to 2D, sum the same element of every channel\n",
    "    feature_maps = []\n",
    "    for layer_output in layer_outputs:\n",
    "      layer_output = layer_output.squeeze(0)\n",
    "      gray_scale = torch.sum(layer_output,0)\n",
    "      gray_scale = gray_scale / layer_output.shape[0]\n",
    "      feature_maps.append(gray_scale.data.cpu().numpy())\n",
    "\n",
    "    print(\"--> fm.shape\")    \n",
    "    for fm in feature_maps:\n",
    "      print(fm.shape)\n",
    "    \n",
    "    return feature_maps, layer_names\n",
    "\n",
    "  def draw_feature_maps(\n",
    "    self,\n",
    "    image,\n",
    "    modelfile=\"\", \n",
    "    weightfile=\"\"  \n",
    "  ):\n",
    "    \"\"\" Extract and plot feature maps for an input image \"\"\"      \n",
    "\n",
    "    # - Retrieve maps\n",
    "    feature_maps, layer_names= self.extract_feature_maps(\n",
    "      image,  \n",
    "      modelfile=modelfile, \n",
    "      weightfile=weightfile  \n",
    "    )\n",
    "    if feature_maps is None:\n",
    "      logger.error(\"Failed to compute feature maps!\")\n",
    "      return -1\n",
    "    \n",
    "    # - Draw maps\n",
    "    fig = plt.figure(figsize=(30, 50))\n",
    "    \n",
    "    for i in range(len(feature_maps)):\n",
    "      ax= fig.add_subplot(5, 4, i+1)\n",
    "      imgplot = plt.imshow(feature_maps[i])\n",
    "      ax.axis(\"off\")\n",
    "      ax.set_title(layer_names[i].split('(')[0], fontsize=30)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4e6b5",
   "metadata": {},
   "source": [
    "## Create dataloaders\n",
    "We are going to create a dataloader for train, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ba7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "##    CREATE DATA LOADERS\n",
    "###############################\n",
    "# - Create data loaders\n",
    "torch.manual_seed(1)\n",
    "batch_size= 64\n",
    "dataloader_train= torch.utils.data.DataLoader(\n",
    "  dataset_train, \n",
    "  batch_size=batch_size,\n",
    "  shuffle=True, \n",
    "  num_workers=1\n",
    ")\n",
    "dataloader_imagenet_train= torch.utils.data.DataLoader(\n",
    "  dataset_imagenet_train, \n",
    "  batch_size=batch_size,\n",
    "  shuffle=True, \n",
    "  num_workers=1\n",
    ")\n",
    "\n",
    "dataloader_val= torch.utils.data.DataLoader(\n",
    "  dataset_val, \n",
    "  batch_size=batch_size,\n",
    "  shuffle=False, \n",
    "  num_workers=1\n",
    ")\n",
    "dataloader_imagenet_val= torch.utils.data.DataLoader(\n",
    "  dataset_imagenet_val, \n",
    "  batch_size=batch_size,\n",
    "  shuffle=False, \n",
    "  num_workers=1\n",
    ")\n",
    "\n",
    "dataloader_test= torch.utils.data.DataLoader(\n",
    "  dataset_test, \n",
    "  batch_size=8,\n",
    "  shuffle=False, \n",
    "  num_workers=1\n",
    ")\n",
    "dataloader_imagenet_test= torch.utils.data.DataLoader(\n",
    "  dataset_imagenet_test, \n",
    "  batch_size=8,\n",
    "  shuffle=False, \n",
    "  num_workers=1\n",
    ")\n",
    "\n",
    "# - Test min/max\n",
    "imgs, targets = next(iter(dataloader_test))\n",
    "print(\"type(imgs)\")\n",
    "print(type(imgs))\n",
    "print(\"imgs.shape\")\n",
    "print(imgs.shape)\n",
    "\n",
    "data_min= torch.amin(imgs, dim=(2,3))\n",
    "data_max= torch.amax(imgs, dim=(2,3))\n",
    "data_absmax= torch.amax(imgs, dim=(1,2,3))\n",
    "print(\"min: \", data_min)\n",
    "print(\"max: \", data_max)\n",
    "print(\"absmax: \", data_absmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdc731",
   "metadata": {},
   "source": [
    "## Create classifier\n",
    "Let's create an instance of the classifier class created above. Change the \"nn_arch\" architecture and relative parameters to customize the network. We will create two classifiers:\n",
    "\n",
    "- custom CNN architecture\n",
    "- resnet18 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789156a8",
   "metadata": {},
   "source": [
    "### Custom architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26bfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Create classifier\n",
    "logger.info(\"Create custom net classifier ...\")\n",
    "nn_arch= \"custom\"\n",
    "classifier= GMNISTClassifier(\n",
    "  nn_arch=nn_arch,\n",
    "  n_conv_layers= 3,\n",
    "  n_filters= [8,16,32],\n",
    "  kern_sizes= [3,5,7],\n",
    "  strides= [1,1,1],\n",
    "  add_maxpool= True,\n",
    "  pool_sizes= 2,\n",
    "  add_batchnorm= True,\n",
    "  n_dense_layers= 1,\n",
    "  dense_layer_sizes= [64],\n",
    "  add_dropout= True,\n",
    "  dropout_prob = 0.5\n",
    ")\n",
    "\n",
    "# - Print architecture\n",
    "logger.info(\"Printing model arch ...\")\n",
    "classifier.print_model_arch(input_shape=(imgs.shape[1],imgs.shape[2],imgs.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b86ed",
   "metadata": {},
   "source": [
    "### Resnet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Create classifier\n",
    "logger.info(\"Create Resnet classifier ...\")\n",
    "nn_arch= \"resnet18\"\n",
    "pretrained_weights=\"DEFAULT\"\n",
    "classifier_resnet= GMNISTClassifier(\n",
    "  nn_arch=nn_arch,\n",
    "  pretrained_weights=pretrained_weights \n",
    ")\n",
    "\n",
    "# - Print architecture\n",
    "logger.info(\"Printing model arch ...\")\n",
    "classifier_resnet.print_model_arch(input_shape=(imgs.shape[1],imgs.shape[2],imgs.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4152bb8",
   "metadata": {},
   "source": [
    "### Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4411a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Set train parameters\n",
    "lr= 1e-4\n",
    "num_epochs= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9c385",
   "metadata": {},
   "source": [
    "### W&B Login\n",
    "Let's initialize weights & biases so that we can monitor \"live\" some information (e.g. losses, accuracies and other metrics) for our training run. For this to work you need to have a wandb account and have set this environment variable on your system: `WANDB_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Initialize wandb\n",
    "import os\n",
    "import shortuuid\n",
    "import wandb\n",
    "\n",
    "logger.info(\"Initialize wandb ...\")\n",
    "\n",
    "wandb_api_key= \"\"\n",
    "log_to_wandb= False\n",
    "\n",
    "\n",
    "if 'WANDB_API_KEY' in os.environ:\n",
    "  wandb_api_key= os.environ['WANDB_API_KEY']\n",
    "  os.environ['WANDB_NOTEBOOK_NAME'] = 'gmnist_classifier'\n",
    "    \n",
    "  if wandb_api_key==\"\":\n",
    "    logger.warning(\"WANDB_API_KEY environment variable read is empty, wont log run metrics!\")\n",
    "else:\n",
    "  logger.warning(\"WANDB_API_KEY environment variable is not defined, wont log run metrics!\")\n",
    "\n",
    "if wandb_api_key!=\"\":\n",
    "  logger.info(\"WANDB_API_KEY is defined and not empty...trying login...\")\n",
    "  try:\n",
    "    wandb.login()\n",
    "    log_to_wandb= True\n",
    "  except Exception as e:\n",
    "    logger.warning(\"Failed to login to wandb (err=%s), won't log run metrics...\" % (str(e)))\n",
    "    log_to_wandb= False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb03d85",
   "metadata": {},
   "source": [
    "## Train classifier\n",
    "Let's train the classifier using architecture and parameters defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b22738",
   "metadata": {},
   "source": [
    "### Custom architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34466f96",
   "metadata": {},
   "source": [
    "Initialize W&B for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Init wandb run\n",
    "if log_to_wandb:\n",
    "  logger.info(\"Initializing wandb for this run ...\")  \n",
    "  os.environ['WANDB_NOTEBOOK_NAME'] = 'gmnist_classifier'\n",
    "    \n",
    "  run_id= shortuuid.uuid()\n",
    "  run_name= \"customnet_lr\" + str(lr) + \"_nepochs\" + str(num_epochs)\n",
    "  wandb_run= wandb.init(\n",
    "    project=\"gmnist-classifier\",\n",
    "    id=run_id,\n",
    "    name=run_name,\n",
    "    config={\n",
    "      \"batch_size\": batch_size,\n",
    "      \"learning_rate\": lr,\n",
    "      \"nepochs\": num_epochs,  \n",
    "      \"dataset\": \"GMNIST\",\n",
    "    }\n",
    "  ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0adac",
   "metadata": {},
   "source": [
    "Start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c05ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Open W&B display\n",
    "if log_to_wandb:\n",
    "  wandb_run.display(height=720)    \n",
    "\n",
    "# - Run train\n",
    "torch.manual_seed(1)\n",
    "metric_hist= classifier.run_train(\n",
    "  train_dl=dataloader_train,\n",
    "  val_dl=dataloader_val,  \n",
    "  num_epochs=num_epochs,  \n",
    "  lr=lr,\n",
    "  log_to_wandb=log_to_wandb,\n",
    "  outfile_prefix=\"model\"\n",
    ")\n",
    "\n",
    "print(\"metrics\")\n",
    "print(metric_hist)\n",
    "\n",
    "# - Terminate wandb\n",
    "if log_to_wandb and wandb.run is not None:\n",
    "  logger.info(\"Terminating wandb ...\")\n",
    "  wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ddb438",
   "metadata": {},
   "source": [
    "Let's plot some metrics after the training run completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14847a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_metric_hist(metric_hist):\n",
    "  \n",
    "  # - Draw losses\n",
    "  x_arr = np.arange(len(metric_hist[\"loss_train\"])) + 1\n",
    "  fig = plt.figure(figsize=(12, 4))\n",
    "  ax = fig.add_subplot(1, 2, 1)\n",
    "  ax.plot(x_arr, metric_hist[\"loss_train\"], '-o', label='Train loss')\n",
    "  ax.plot(x_arr, metric_hist[\"loss_val\"], '--<', label='Validation loss')\n",
    "    \n",
    "  ax.legend(fontsize=8)\n",
    "  ax = fig.add_subplot(1, 2, 2)\n",
    "  \n",
    "  # - Draw accuracy/f1score\n",
    "  ax.set_ylim(0,1)  \n",
    "  ax.plot(x_arr, metric_hist[\"acc_train\"], '-o', label='Train acc.')\n",
    "  ax.plot(x_arr, metric_hist[\"acc_val\"], '--<', label='Validation acc.')\n",
    "  ax.plot(x_arr, metric_hist[\"f1score_train\"], '-*', label='Train F1-score')\n",
    "  ax.plot(x_arr, metric_hist[\"f1score_val\"], '-->', label='Validation F1-score')  \n",
    "  ax.legend(fontsize=8)\n",
    "  ax.set_xlabel('Epoch', size=15)\n",
    "  ax.set_ylabel('Accuracy/F1-score', size=15)\n",
    "\n",
    "  plt.show()  \n",
    "    \n",
    "logger.info(\"Plotting train run metrics ...\")\n",
    "draw_metric_hist(metric_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776965a4",
   "metadata": {},
   "source": [
    "### Resnet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb1365",
   "metadata": {},
   "source": [
    "Initialize W&B for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35804c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Init wandb run\n",
    "if log_to_wandb:\n",
    "  logger.info(\"Initializing wandb for this run ...\")  \n",
    "  os.environ['WANDB_NOTEBOOK_NAME'] = 'gmnist_classifier'\n",
    "    \n",
    "  run_id= shortuuid.uuid()\n",
    "  run_name= \"resnet_lr\" + str(lr) + \"_nepochs\" + str(num_epochs)\n",
    "  wandb_run= wandb.init(\n",
    "    project=\"gmnist-classifier\",\n",
    "    id=run_id,\n",
    "    name=run_name,\n",
    "    config={\n",
    "      \"batch_size\": batch_size,\n",
    "      \"learning_rate\": lr,\n",
    "      \"nepochs\": num_epochs,  \n",
    "      \"dataset\": \"GMNIST\",\n",
    "    }\n",
    "  )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d53f4",
   "metadata": {},
   "source": [
    "Start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Open W&B display\n",
    "if log_to_wandb:\n",
    "  wandb_run.display(height=720)  \n",
    "\n",
    "# - Run train\n",
    "torch.manual_seed(1)\n",
    "metric_hist_resnet= classifier_resnet.run_train(\n",
    "  train_dl=dataloader_imagenet_train,\n",
    "  val_dl=dataloader_imagenet_val,  \n",
    "  num_epochs=num_epochs,  \n",
    "  lr=lr,\n",
    "  log_to_wandb=log_to_wandb,\n",
    "  outfile_prefix=\"resnet_model\"\n",
    ")\n",
    "\n",
    "print(\"metrics\")\n",
    "print(metric_hist_resnet)\n",
    "\n",
    "# - Terminate wandb\n",
    "if log_to_wandb and wandb.run is not None:\n",
    "  logger.info(\"Terminating wandb ...\")\n",
    "  wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b58ec",
   "metadata": {},
   "source": [
    "Let's plot some metrics after the training run completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2927d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Plotting train run metrics ...\")\n",
    "draw_metric_hist(metric_hist_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1b32f",
   "metadata": {},
   "source": [
    "## Test model\n",
    "Let's load the saved trained model and run inference on test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b698f",
   "metadata": {},
   "source": [
    "### Custom architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Run inference on test set\n",
    "logger.info(\"Running inference on test data ...\")\n",
    "metrics_test= classifier.run_test(\n",
    "  dataloader=dataloader_test,\n",
    "  weightfile=\"model_weights.pth\"  \n",
    ")\n",
    "\n",
    "print(\"--> metrics (TEST)\")\n",
    "print(metrics_test)\n",
    "\n",
    "# - Draw confusion matrix\n",
    "logger.info(\"Drawing confusion matrix for test set ...\")\n",
    "fig_, ax_ = metrics_test[\"cm_metric\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b2b5d",
   "metadata": {},
   "source": [
    "Let's plot the feature maps for a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9175a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Take a sample image from the test dataset\n",
    "data_index= 0 # take the first\n",
    "image, target= dataset_test[data_index]\n",
    "label= dataset_test.target2label[target]\n",
    "image= image.unsqueeze(0)\n",
    "\n",
    "print(\"image\")\n",
    "print(type(image))\n",
    "print(image.shape)\n",
    "\n",
    "# - Draw feature maps\n",
    "classifier.draw_feature_maps(\n",
    "  image,\n",
    "  weightfile=\"model_weights.pth\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7eb5ba",
   "metadata": {},
   "source": [
    "Let's plot the gradCAM to inspect model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4578d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Run gradCAM on some test data\n",
    "logger.info(\"Running gradCAM on test data ...\")\n",
    "target_layers= [\"relu3\"]\n",
    "classifier.plot_sample_predictions(\n",
    "  dataset=dataset_test,\n",
    "  dataset_gradcam=dataset_test,\n",
    "  weightfile=\"model_weights.pth\", \n",
    "  plot_gradcam=True,\n",
    "  layer_names=target_layers,\n",
    "  gradcam_method=\"gradcam\",\n",
    "  aug_smooth=False,\n",
    "  eigen_smooth=False,\n",
    "  gradcam_alpha=0.5,\n",
    "  apply_heatmap_thr=True,\n",
    "  heatmap_thr=0.1 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8879727",
   "metadata": {},
   "source": [
    "### Resnet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89974fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Run inference on test set\n",
    "logger.info(\"Running inference on test data ...\")\n",
    "metrics_resnet_test= classifier_resnet.run_test(\n",
    "  dataloader=dataloader_imagenet_test,\n",
    "  weightfile=\"resnet_model_weights.pth\"  \n",
    ")\n",
    "\n",
    "print(\"--> metrics (TEST)\")\n",
    "print(metrics_resnet_test)\n",
    "\n",
    "# - Draw confusion matrix\n",
    "logger.info(\"Drawing confusion matrix for test set ...\")\n",
    "fig_, ax_ = metrics_resnet_test[\"cm_metric\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b110d6f",
   "metadata": {},
   "source": [
    "Let's plot the feature maps for a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Take a sample image from the test dataset\n",
    "data_index= 0 # take the first\n",
    "image, target= dataset_imagenet_test[data_index]\n",
    "label= dataset_imagenet_test.target2label[target]\n",
    "image= image.unsqueeze(0)\n",
    "\n",
    "print(\"image\")\n",
    "print(type(image))\n",
    "print(image.shape)\n",
    "\n",
    "# - Draw feature maps\n",
    "classifier_resnet.draw_feature_maps(\n",
    "  image,\n",
    "  weightfile=\"resnet_model_weights.pth\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91042bce",
   "metadata": {},
   "source": [
    "Let's plot the gradCAM to inspect model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8687b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Run gradCAM on some test data\n",
    "logger.info(\"Running gradCAM on test data ...\")\n",
    "target_layers= [\"layer4\"]\n",
    "classifier_resnet.plot_sample_predictions(\n",
    "  dataset=dataset_imagenet_test,\n",
    "  dataset_gradcam=dataset_test,\n",
    "  weightfile=\"resnet_model_weights.pth\", \n",
    "  plot_gradcam=True,\n",
    "  layer_names=target_layers,\n",
    "  gradcam_method=\"gradcam\",\n",
    "  aug_smooth=False,\n",
    "  eigen_smooth=False,\n",
    "  gradcam_alpha=0.3,\n",
    "  apply_heatmap_thr=True,\n",
    "  heatmap_thr=0.5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b0cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc8-ai-workshop",
   "language": "python",
   "name": "usc8-ai-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
